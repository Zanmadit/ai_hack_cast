{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5a64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF file\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    \n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text = page.get_text()\n",
    "        full_text += text + \"\\n\"\n",
    "    \n",
    "    doc.close()\n",
    "    \n",
    "    # Clean the text\n",
    "    full_text = re.sub(r'\\s+', ' ', full_text)\n",
    "    full_text = re.sub(r'\\n+', '\\n', full_text)\n",
    "    \n",
    "    return full_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756d08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='colbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11598ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=512, overlap=128):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks\n",
    "    chunk_size: approximate number of words per chunk\n",
    "    overlap: number of overlapping words between chunks\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e708a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alisher/projects/america_ahhahh/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from colbert import Indexer\n",
    "from colbert.infra import Run, RunConfig\n",
    "from colbert.data import Queries, Collection\n",
    "\n",
    "def initialize_colbert(index_name=\"pdf_index\", experiment_name=\"pdf_experiment\"):\n",
    "    \"\"\"Initialize ColBERT with configuration\"\"\"\n",
    "    \n",
    "    # Configure ColBERT run\n",
    "    with Run().context(RunConfig(nranks=1, experiment=experiment_name)):\n",
    "        config = {\n",
    "            'doc_maxlen': 512,  # Max document length in tokens\n",
    "            'query_maxlen': 128,  # Max query length in tokens\n",
    "            'dim': 256,  # Embedding dimension\n",
    "            'similarity': 'cosine',\n",
    "            'checkpoint': 'colbert-ir/colbertv2.0'  # Use ColBERT v2.0 checkpoint\n",
    "        }\n",
    "        \n",
    "    return config, index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78bf61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_collection(pdf_path):\n",
    "    \"\"\"Prepare document collection from PDF\"\"\"\n",
    "    \n",
    "    # Extract text\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Chunk the text\n",
    "    chunks = chunk_text(text, chunk_size=512, overlap=128)\n",
    "    \n",
    "    # Create a collection with metadata\n",
    "    collection = []\n",
    "    metadata = []\n",
    "    \n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        collection.append(chunk)\n",
    "        metadata.append({\n",
    "            'chunk_id': idx,\n",
    "            'source': pdf_path,\n",
    "            'text': chunk[:100] + '...'  # Store preview\n",
    "        })\n",
    "    \n",
    "    return collection, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd27547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert import Indexer\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "import torch\n",
    "\n",
    "def index_documents(collection, index_name=\"pdf_index\"):\n",
    "    \"\"\"Index the document collection using ColBERT\"\"\"\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device == \"cuda\":\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    with Run().context(RunConfig(nranks=1, gpus=1)):\n",
    "        config = ColBERTConfig(\n",
    "            doc_maxlen=512,\n",
    "            nbits=2,  # Compression bits\n",
    "            kmeans_niters=4,\n",
    "            checkpoint='colbert-ir/colbertv2.0'\n",
    "        )\n",
    "        \n",
    "        indexer = Indexer(checkpoint=\"colbert-ir/colbertv2.0\", config=config)\n",
    "        \n",
    "        # Create index\n",
    "        indexer.index(\n",
    "            name=index_name,\n",
    "            collection=collection,\n",
    "            overwrite=True\n",
    "        )\n",
    "        \n",
    "        indexer.get_index()\n",
    "    \n",
    "    return indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009160a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert import Searcher\n",
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "import torch\n",
    "\n",
    "def search_pdf(query, index_name=\"pdf_index\", k=5):\n",
    "    \"\"\"Search the indexed PDF content\"\"\"\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device for search: {device}\")\n",
    "    \n",
    "    with Run().context(RunConfig(nranks=1, gpus=1)):\n",
    "        config = ColBERTConfig(\n",
    "            checkpoint='colbert-ir/colbertv2.0'\n",
    "        )\n",
    "        \n",
    "        searcher = Searcher(index=index_name, config=config)\n",
    "        \n",
    "        # Search - returns a Ranking object with passage_ids and scores\n",
    "        results = searcher.search(query, k=k)\n",
    "        \n",
    "        # Format results\n",
    "        search_results = []\n",
    "        \n",
    "        # ColBERT returns a list where each item is (passage_id, rank, score)\n",
    "        # or just the ranking indices\n",
    "        for rank, (passage_id, score) in enumerate(zip(results[0], results[1])):\n",
    "            search_results.append({\n",
    "                'passage_id': passage_id,\n",
    "                'rank': rank + 1,\n",
    "                'score': score\n",
    "            })\n",
    "        \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2822cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_pdf_with_colbert(pdf_path, index_name=\"pdf_index\"):\n",
    "    \"\"\"Complete pipeline to embed PDF with ColBERT v2.0\"\"\"\n",
    "    \n",
    "    print(\"Step 1: Extracting text from PDF...\")\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    print(\"Step 2: Chunking document...\")\n",
    "    chunks = chunk_text(text, chunk_size=256, overlap=32)\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "    \n",
    "    print(\"Step 3: Initializing ColBERT...\")\n",
    "    config, index_name = initialize_colbert(index_name=index_name)\n",
    "    \n",
    "    print(\"Step 4: Preparing collection...\")\n",
    "    collection, metadata = prepare_collection(pdf_path)\n",
    "    \n",
    "    print(\"Step 5: Indexing documents...\")\n",
    "    indexer = index_documents(collection, index_name)\n",
    "    \n",
    "    print(\"Step 6: Index created successfully!\")\n",
    "    \n",
    "    # Save metadata for later reference\n",
    "    import json\n",
    "    with open(f\"{index_name}_metadata.json\", \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    return index_name, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37539a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"asda.pdf\"\n",
    "    index_name, metadata = embed_pdf_with_colbert(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ef168a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for search: cuda\n",
      "[Nov 02, 17:28:49] #> Loading codec...\n",
      "[Nov 02, 17:28:49] #> Loading IVF...\n",
      "[Nov 02, 17:28:49] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 3912.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nov 02, 17:28:49] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 1073.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: Efficiency of AI, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 8122, 1997, 9932,  102,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
      "         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "Rank 1: Score 1.0000\n",
      "Content: and in some settings, language model agents even outperformed humans in programming tasks with limit...\n",
      "--------------------------------------------------\n",
      "Rank 2: Score 2.0000\n",
      "Content: What a year 2024 has been for AI. The recognition of AI’s role in advancing humanity’s knowledge is ...\n",
      "--------------------------------------------------\n",
      "Rank 3: Score 3.0000\n",
      "Content: (cont’d) 6. Global AI optimism is rising—but deep regional divides remain. In countries like China (...\n",
      "--------------------------------------------------\n",
      "Rank 4: Score 4.0000\n",
      "Content: Artiﬁcial Intelligence Index Report 2025 Artiﬁcial Intelligence Index Report 2025 1 Welcome to the e...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Efficiency of AI\"\n",
    "results = search_pdf(query, index_name=index_name, k=5)\n",
    "\n",
    "# Display results with metadata\n",
    "for result in results:\n",
    "    passage_id = result['passage_id']\n",
    "    print(f\"Rank {result['rank']}: Score {result['score']:.4f}\")\n",
    "    print(f\"Content: {metadata[passage_id]['text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66bda406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_id': 1,\n",
       " 'source': 'asda.pdf',\n",
       " 'text': 'What a year 2024 has been for AI. The recognition of AI’s role in advancing humanity’s knowledge is ...'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad33a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
